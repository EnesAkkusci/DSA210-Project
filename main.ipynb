{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The main data I will use in this project comes from YouTube which is my watch history data. It was sent by YouTube per my request in html format. Since I intend to use pandas and plotly for data visualasation purposes the first order of business will be to clean up the html data and conver it to csv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ads\n",
    "\n",
    "The html file containing the data related to my watch history also included the ads I watche. Below I clean the data of those ads which there were about 9.5k ads among the 55k total videos I have watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: Data\\izleme geçmişi.html\n",
      "Found 9568 ads\n",
      "Cleaned HTML saved to Data\\addfree_data.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "# Define the path to the HTML file\n",
    "data_file = Path(\"Data\") / \"izleme geçmişi.html\"\n",
    "\n",
    "# Check if the file exists\n",
    "if data_file.exists():\n",
    "    print(f\"File found: {data_file}\")\n",
    "else:\n",
    "    print(\"File not found!\")\n",
    "\n",
    "# Open and parse the file\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    soup = BeautifulSoup(file, \"lxml\")\n",
    "\n",
    "ads = soup.find_all(string=lambda text: text and \"Google Reklamlar\" in text.replace(\"\\xa0\", \" \").strip())\n",
    "print(f\"Found {len(ads)} ads\")  # Debugging: Output the number of matches\n",
    "\n",
    "for ad in ads:\n",
    "    ad_div = ad.find_parent(\"div\", class_=lambda classes: classes and \"outer-cell\" in classes and \"mdl-cell--12-col\" in classes)\n",
    "    if ad_div:\n",
    "        ad_div.decompose()\n",
    "\n",
    "\n",
    "# Save the cleaned chunk\n",
    "cleaned_data_path = Path(\"Data\") / \"addfree_data.html\"\n",
    "with open(cleaned_data_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(soup.prettify())\n",
    "\n",
    "print(f\"Cleaned HTML saved to {cleaned_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "# Define the path to the cleaned HTML file\n",
    "data_file = Path(\"Data\") / \"cleaned_chunk.html\"\n",
    "\n",
    "# Open and parse the file\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    soup = BeautifulSoup(file, \"lxml\")  # Using lxml for faster parsing\n",
    "\n",
    "# Find all strings containing \"yayını görüntülendi\"\n",
    "posts = soup.find_all(string=lambda text: text and \"yayını görüntülendi\" in text)\n",
    "\n",
    "print(f\"Found {len(posts)} community post records.\")  # Debugging: Output the number of matches\n",
    "\n",
    "# Remove parent divs containing these records\n",
    "for post in posts:\n",
    "    post_div = post.find_parent(\"div\", class_=lambda classes: classes and \"outer-cell\" in classes and \"mdl-cell--12-col\" in classes)\n",
    "    if post_div:\n",
    "        print(f\"Removing community post div: {post_div}\")  # Debugging: Confirm removal\n",
    "        post_div.decompose()\n",
    "\n",
    "# Save the cleaned HTML\n",
    "cleaned_file_path = Path(\"Data\") / \"ncp_chunk.html\"\n",
    "with open(cleaned_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(soup.prettify())\n",
    "\n",
    "print(f\"Cleaned HTML saved to {cleaned_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
